# BSAN 6080 reMarkable Project
![alt text](tablet.jpg)

# Table of Content
* [Sprint 1: ](https://github.com/LMU-MSBA/bsan-6080-reMarkable#sprint-1)
* [1. Business Understanding Phase](https://github.com/LMU-MSBA/bsan-6080-reMarkable#business-understanding-phase)
	* [1.1 Determine Business Objective](https://github.com/LMU-MSBA/bsan-6080-reMarkable#11-determine-business-objective-)
	* [1.2 Assess Situation](https://github.com/LMU-MSBA/bsan-6080-reMarkable#12-assess-situation-)
	* [1.3 Determine Data Mining Goals](https://github.com/LMU-MSBA/bsan-6080-reMarkable#13-determine-data-mining-goals-)
	* [1.4 Produce Project Plan](https://github.com/LMU-MSBA/bsan-6080-reMarkable#14-produce-project-plan-)
* [Sprint 2: ](https://github.com/LMU-MSBA/bsan-6080-reMarkable#sprint-2)
* [2. Data Understanding Phase](https://github.com/LMU-MSBA/bsan-6080-reMarkable#data-understanding-phase)
	* [2.1 Collect Initial Data](https://github.com/LMU-MSBA/bsan-6080-reMarkable#21-collect-initial-data-)
	* [2.2 Describe Data](https://github.com/LMU-MSBA/bsan-6080-reMarkable#22-describe-data-)
	* [2.3 Explore Data](https://github.com/LMU-MSBA/bsan-6080-reMarkable#23-explore-data-)
	* [2.4 Verify Data Quality](https://github.com/LMU-MSBA/bsan-6080-reMarkable#24-verify-data-quality-)
* [Sprint 3: ](https://github.com/LMU-MSBA/bsan-6080-reMarkable#sprint-3)
* [3. Data Preparation Phase](https://github.com/LMU-MSBA/bsan-6080-reMarkable#data-preparation-phase)
	* [3.1 Select Data](https://github.com/LMU-MSBA/bsan-6080-reMarkable#31-select-data-)
	* [3.2 Clean Data](https://github.com/LMU-MSBA/bsan-6080-reMarkable#32-clean-data-)
	* [3.3 Construct Data](https://github.com/LMU-MSBA/bsan-6080-reMarkable#33-construct-data-)
	* [3.4 Integrate Data](https://github.com/LMU-MSBA/bsan-6080-reMarkable#34-integrate-data-)
	* [3.5 Format Data](https://github.com/LMU-MSBA/bsan-6080-reMarkable#35-format-data-)
* [4. Modeling Phase](https://github.com/LMU-MSBA/bsan-6080-reMarkable#modeling-phase)
	* [4.1 Selecting Modeling Techniquies](https://github.com/LMU-MSBA/bsan-6080-reMarkable#41-selecting-modeling-techniquies-)
	* [4.2 Generate Test Design](https://github.com/LMU-MSBA/bsan-6080-reMarkable#42-generate-test-design-)
	* [4.3 Build Model](https://github.com/LMU-MSBA/bsan-6080-reMarkable#43-build-model-)
	* [4.4 Assess Model](https://github.com/LMU-MSBA/bsan-6080-reMarkable#44-assess-model-)
* [5. Evaluation Phase](https://github.com/LMU-MSBA/bsan-6080-reMarkable#evaluation-phase)
	* [5.1 Evaluate Results](https://github.com/LMU-MSBA/bsan-6080-reMarkable#51-evaluate-results-)
	* [5.2 Review Process](https://github.com/LMU-MSBA/bsan-6080-reMarkable#52-review-process-)
	* [5.3 Determine Next Steps](https://github.com/LMU-MSBA/bsan-6080-reMarkable#53-determine-next-steps-)
* [Sprint 4:](https://github.com/LMU-MSBA/bsan-6080-reMarkable#sprint-4-)
* [6. Deployment Phase](https://github.com/LMU-MSBA/bsan-6080-reMarkable#deployment-phase-)
	* [6.1 Plan Deployment](https://github.com/LMU-MSBA/bsan-6080-reMarkable#61-plan-deployment-)
	* [6.2 Plan Monitoring & Maintenance](https://github.com/LMU-MSBA/bsan-6080-reMarkable#62-plan-monitoring--maintenance-)
	* [6.3 Product Final Report](https://github.com/LMU-MSBA/bsan-6080-reMarkable#63-product-final-report-)
	* [6.4 Review Project](https://github.com/LMU-MSBA/bsan-6080-reMarkable#64-review-project-)

# Sprint 1: 
# Business Understanding Phase
## 1.1 Determine Business Objective [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)
### Background: 
reMarkable is a Norwegian-based tablet company that was founded in early 2014. It produces a specialized electronic-ink tablet whose main focus is to replicate the experiences users have with paper such as writing, drawing, and reading. reMarkable position intersects three markets; smart tablets, physical book substitutes, and drawing tablets, therefore allowing the company to compete with a diverse array of companies from well-known brands such as Apple’s iPad and Amazon’s Kindle to smaller companies such as SuperNote and Boox. 

### Business Objectives: 
* **Product Design**: 
The first business objective is to identify specific and actionable customer needs and pain points to inform and aid the engineering department in designing our next product. reMarkable is currently selling the second iteration of its tablet. There is sufficient consumer feedback from the company's official feedback channels as well as on third-party websites such as Amazon and Twitter, which is packed with crucial user-generated content (UGC) waiting to be extracted and implemented. 

* **Marketing**:
The second objective is to formulate our marketing processes, which consist of Segmentation, Targeting, and Positioning. 
First we need to determine how our current and potential customers are segmented which will help us identify specific attributes within the segments. This process is crucial for us to understand our customers and effectively target the audience interested in our products. Our team will use the information from our customer segmentation to determine how customers perceive our brand and products, and strategically reposition ourselves to fit the type of brand we want to be. 

### Business Success Criteria
In the short term, our success criteria is to increase product sales by 20% and achieve higher customer satisfaction. In the long run, we hope to help design a better reMarkable3 where the success will be measured by the product’s sales and customer feedback. 


## 1.2 Assess Situation [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)
### Inventory of resources
**Personnel**: 
We have a diverse team of six well-rounded individuals who possess strong business understanding. Each person brings unique value to the project. 
* Alena: Has experience using CRISP-DM and is the project owner responsible for the overall project planning.
* Rana: Has deep marketing understanding, fluent in Norwegian language, and has connections with individuals in Norway (possibly with somebody in the managerial position at reMarkable).
* Krissy: Has strong marketing understanding and an understanding of US local markets.
* Oliver: Is a data mining expert and has strong presentation skills.
* Daniel: Has extensive work experience in business.
* Arshak: Is a data mining expert.
We also are privileged to have four LMU professors actively helping us in the process.
 
**Data**:
We have developed programming codes and have obtained the keys for data collection with API’s such as Amazon API, Twitter API, Yelp API and Web scraping.
We strive to obtain insight sales and revenue data from reMarkable, if possible.
 
**Computing resources**:
We have 6 laptops (2 Macs, 4 Windows), 1 PC, access to LMU Computer Labs and VDI. In addition, we can utilize cloud sources such as Google Colab, Deepnote, AWS, etc.
 
**Software**:
We will be using Colab and Deepnote for Python. We expect to use libraries such as Axesso API, Request API, Pandas, Tweepy API, etc. Most are either free or will be included in the budget.
For visualization purposes we might be using Tableau with the student account.
 
### Requirements, assumptions, and constraints
Schedule of completion:
The schedule of completion is based on the sprints scheduled by the professor and is fully documented in the planning section completed by Alena.
We use Trello to manage time and tasks.
 
### Comprehensibility:
We assume our audience has a basic understanding of technical aspects of our project such as Machine Learning, API’s, Jupyter Notebooks, etc. With this assumption, we will present our findings and results to stakeholders in a language that would be understood by an average college educated person. 
We will use simple graphs and explanations in our presentation together with Q&A’s and references for complex terms.
 
**Quality of results:**
We assume that UGC for reMarkable contains useful customer insights and that these insights can be extracted using our data extraction methods. This assumption is based on articles in scientific literature and our experiences with similar projects.
As an example of such article please refer to Identifying Customer Needs from User-Generated Content
Artem Timoshenko, John R. Hauser
 
**Security:**
We believe that security is not a major issue since most of the collected data is publicly available on Social Media and Amazon.
If we are lucky enough to get insight data through Rana’s Norwegian connections, we will sign NDA and follow all necessary safety protocols including but not limited to Password encryption, Separate accounts for the project (non-personal), Limiting the circle of consultants (all sign NDA). 

**Legal issues:**
In addition to the aforementioned statements, we believe that on the rights of an Educational Project we can execute our project plan fully with no legal confrontations with the company.
Make sure that you are allowed to use the data
We are allowed to use the data as long as we have the appropriate keys for API’s. For example, when using Twitter Academic API, we need to properly describe our project to Twitter.
 
### Risks and contingencies
API’s might stop working (recently happened with Facebook API). In the event that our API’s stopped working, we will change our data source accordingly. For example, instead of using Twitter we can use Reddit, Instead of Amazon reviews, Blog Posts.
Some of our teammates might get too busy with their jobs and not be able to meet their personal deadlines for sprints. In this situation, we will rearrange tasks accordingly and delegate the workload to third parties. We will keep each other accountable and be transparent with our stakeholders in the process of our project. 
If we are not able to extract customer needs from UGC we will then find other ways to generate insight from the company either using different data sources or conducting a different type of analysis. 
The company might get acquired and lose its independence and might not need our project anymore. We will make sure that this is accounted for in the contract (theoretically) so that the team is paid off. In this event, we will be pitching our project to the company who acquired reMarkable.
And many more scenarios. In any situation we would reassess the situation and move forward with the best understanding of the problem at the time.
 
### Terminology
**Business Understanding**

Customer Segmentation: Identifying groups of customers based on their characteristics.

Targeting: Choosing customers segments to target (act upon). Designing marketing strategies for each chosen customer segment.

Positioning: Relates to where we position our product in the mind of the customer. This part is crucial especially for our drawing tablet/book product since there are many similar products on the market that have slightly different combinations of attributes and benefits.

Product Attribute: A physical characteristic of a product. For example: black and white E-ink display.

Customer Benefit: A benefit that a customer gets that is related to a Product Attribute. For example: thanks to the E-ink display, customers enjoy less strain on their eyes and can read and draw even outside on a sunny day.
 
**Data Mining**
API: application programming interface is used to connect programs with other programs. In our case it will be used to connect Python or Jupyter Notebook to Twitter and Amazon to get the data programmatically as opposed to manual scraping.
 
Word Embedding: A process of converting words into numbers in a way that reflects the meaning of the words. This allows the computer to perform analytical operations on these words (reviews), particularly to extract customer needs.
 
### Costs and benefits
**Expected Costs:**

Construct a cost-benefit analysis for the project, which compares the costs of the project with the potential benefits to the business. The comparison should be as specific as possible. For example, use monetary measures in a commercial situation:
Total Costs: $32,526
Pay for personnel:
6 people * $50/h * 10h/week * 8 weeks = $24,000
Cost of software:
Tableau License if not provided by LMU: $70 per month * 6 people * 2 months = $840
Axesso API for Amazon Reviews: $90 per month * 2 months = $180. (might increase to $700 if we need more data, there are different plans)
30% overhead for the budget, in case of urgent costs not accounted for here.

**Expected benefits:**

It is difficult to directly estimate the benefits for the company if the project is successful.
Some of the possible benefits include:
20% increase in sales.
10% increase in market share.
Average 0.8 points increase in customer satisfaction (based on reviews)
Better product. At least 2 product improvements based on customer needs.
Better positioning. At least 2 new developments of distinctive assets for the product and the company.
Ability to reuse our methodology for future research and improvements.


## 1.3 Determine Data Mining Goals [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)

### Data Mining Goals
Our main data mining goal is to obtain insightful data which will help us achieve our aforementioned business objectives. 
To achieve this, we must implement ETL (extract, transform, and load) on all of the different sources of information. We will most likely not be using clean data since we will obtain most data from the original source, UGC. This makes it even more crucial to properly inspect the raw data and implement ETL in order to have usable data. 
In addition to applying ETL on each data source independently, we must ensure that we have uniformity across the different sources. One of our business goals is to identify customer needs and since this is not to be done in silo based on the different sources, but rather as an aggregate study, we must be able to utilize all of our data sets together. Having clean and uniform data will allow us to use the data set to carry out our investigation. Another business goal is to inform the marketing STP (Segmentation, Targeting, & Positioning). This process will require the analysis of the aggregate data therefore all data must be joined together to form one large data set where we will use it for our analysis. 

### Data Mining Success Criteria
In order to measure the success of our data mining we must set certain criterias. 
The most basic is “is this dataset usable?”. This can be determined by making sure our dataset will load into the chosen software (Google Colab, Deepnote…). If it is not formatted so that it is usable in the desired platform, then the data has no value to this project. 
Another criteria in determining the success of our data mining, is whether we can extract at least 2 new customer needs and/or pain points from the analyzed UGC. If we are unable to extract this information from the dataset, we will need to gather additional data from the same sources or different platforms. 
Another criteria is making sure that we are able to properly create an STP model from our dataset. We should be able to segment our audience so that the marketing team can target new customers. Should we not have sufficient information to segment our audience, we would need to obtain additional data. 

## 1.4 Produce Project Plan [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)

In order to complete our desired goals for this project, we decided to utilize Agile methodologies to assist with project management. Specifically, we will be using Trello to assign tasks to ensure we hit our various sprint goals as well as to keep all project related material in one place. Furthermore, we will use WhatsApp for any necessary quick and instant messaging. Lastly, the team has agreed to have a weekly meeting every Tuesday at 5:00 P.M. until the completion of our project, so that we can communicate where everyone is with their assigned tasks and keep the team on the same page at various points throughout the project. Down below is more information on the specifics of each Sprint and how we plan to reach these various milestones.

* Sprint 0: Project Proposal (Expected Completion Date: 03/15/2022)
	
	Deliverables: 
Project proposal
Job post

This Sprint has been completed and a GitHub Repository for the project has been created.

* Sprint 1: Business Understanding (Expected Completion Date: 03/29/2022)
	
	Deliverables: 
Documented CRISP-DM Business Understanding Tasks and Outputs
Create and Update Trello Board

In order to complete this sprint all team members must first create Trello accounts, so that all members have access to a central Trello board for this project. Additionally, a meeting will be necessary to breakdown and discuss specific tasks that need to be done to complete Business Understanding CRISP-DM documentation.

* Sprint 2: Data Understanding (Expected Completion Date: 04/12/2022)
	
	Deliverables: 
Documented CRISP-DM Data Understanding Tasks and Outputs
Data Collection Jupyter Notebook (data_collection.ipynb)
Exploratory Data Analysis Jupyter Notebook (eda.ipynb)
Update Trello Board

As we plan to analyze User Generated Content from Twitter, we plan to use Jupyter Notebooks and a simple Twitter API calls to extract the data (tweets) that will be necessary for the project. Additionally, a meeting will be necessary to breakdown and discuss the specific tasks that need to be done to complete Data Understanding CRISP-DM documentation.


* Sprint 3: Data Preparation, Modeling, Evaluation (Expected Completion Date: 04/26/2022)
	
	Deliverables:
Documented CRISP-DM Data Preparation, Modeling, and Evaluation Tasks and Outputs
Data Preparation Jupyter Notebook (data_preparation.ipynb)
Machine Learning Models Jupyter Notebook (models.ipynb)
Machine Learning Models Saved as Pickle Files
Update Trello Board
AWS Database Connection Details (aws_db_project_name.txt)

For Sprint 3, we will continue to utilize Jupyter Notebooks for both prepping our data for the model and to run the BERT model that we plan to use to analyze the Tweets. Additionally, we plan to run K-Means Clustering analysis that will also be done with Python to run a thorough marketing analysis on the data that will allow us to segment, target, and position ReMarkable. According to the model assessment, we will revise parameter settings and tune them for different iterations. We will continue to model until we believe we have found the best model and clustering. All iterations (revisions and assessments) will be documented in Trello.

This workload may seem unachievable for one Sprint, but with the BERT model already available to us, this will likely be possible to complete in a timely manner. Lastly, a meeting will be necessary to breakdown and discuss the specific tasks that need to be done to complete Data Preparation, Modeling, and Evaluation CRISP-DM documentation.

* Sprint 4: Deployment (Expected Completion Date: 05/06/2022)
	
	Deliverables:
Documented CRISP-DM Deployment Tasks and Outputs
Dashboards
Machine Learning API URL Endpoint
Slides (presentation.pdf)
Update Trello Board
Peer Evaluation
Q&A 

For the final sprint, we will use the Matplotlib package in Python to create visualizations as well as Tableau to create dashboards of our findings. We will also create a presentation deck on Google Slides and prepare for our final presentation. Lastly, a meeting will be necessary to breakdown and discuss the specific tasks that need to be done to complete the Deployment CRISP-DM documentation.


# Sprint 2: 
# Data Understanding Phase
## 2.1 Collect Initial Data [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)

### Initial Data Collection Report
Initially, we wanted to gather data from 2 sources.

Twitter through **Twitter Academic API v2** and **Amazon through Axesso API**.

Unfortunately, reMarkable2 is not available on Amazon and the reviews on reMarkable1 were sparse and not useful. Hence, we decided to go with Twitter.


We obtained a key for Twitter Academic API v2 and planned to collect 50,000 tweets.

We collected **2400 Tweets** on reMarkable2. These are **actually all of the tweets** that mention reMarkable2. And they go back up to 2019, the year the product was launched.

The following is the query we used:

**query = 'reMarkable2 lang:en -is:retweet'**

Since we are primarily going to use **Python** in our future analysis, we performed the data collection via **Google Colab** and saved the dataset directly to **Google Drive** for easy access and transparency between all team members.
For Data manipulation we used **Pandas** library



Other than the text of the Tweets the dataset provides:


**tweet.public_metrics**

{'retweet_count': 1, 'reply_count': 0, 'like_count': 15, 'quote_count': 1}


**user.public_metrics:**

{'followers_count': 3719, 'following_count': 2607, 'tweet_count': 13414, 'listed_count': 249}

Both can be easily “exploded” into separate columns for future analysis via

 df[‘column’].apply(pd.Series) // using Pandas
 

**breakdown by client, etc:**

Twitter for Android

Twitter Web App

Twitter for iPhone


Depending on the results of future analysis, we are planning to collect more Tweets on other keywords related to reMarkable2.





### Initial Data Cleaning Report
Since the primary data we collected are tweets from Twitter, so the data cleaning consists mainly of text cleaning. And we used Regular Expression to accomplish that.

Things to Clean:
* Encoding Issue: oftentimes when exporting tweets from Twitter API to csv files, there might be some sort of encoding errors that would result in strings containing strange characters. For example, “I have always continued to write âœðŸ¼ with a pencil”
* Remove links: many tweets contain links to a photo or a video, and sometimes a website. These strings do not contribute to our analysis. So they should be removed from our data.
* @ and #: Most tweets contain many @ and # which allowed the tweets to be identified in certain topics. However, when querying tweets on a certain topic, the @ and # will be very repetitive most of the time. In our case, there might be a lot of “@reMarkable”, or “#tablet”, and these words might skew out text analysis later, so we think that should be removed.

We wrote a function for cleaning these things. We used .encode() method to use ACSII encoding, removing the odd character. And then several regex expression to remove the links, @ and #. 

The python code looks like this: 
```ruby
import regex as re
def clean_tweets(sent):
    # put everythin in lower case
    sent = sent.lower()
    # encode to ascii unicode, it removes strange characters
    sent = sent.encode('ascii', 'ignore').decode() 
    # remove https
    sent = re.sub(r'https\S+', '', sent)    
    # remove http
    sent = re.sub(r'http\S+', '', sent)   
    # remove @
    sent = re.sub(r'@\S+', '', sent)     
    # remove #
    sent = re.sub(r'#\S+', '', sent) 
    sent = " ".join(sent.split())
    return sent
```

## 2.2 Describe Data [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)
### Data Decription Report

In this data description section, we aim to examine the surface properties of the acquired data, in order to ensure the validity and/or caution we need to take, should we find any limiting records.  We generate the table below to summarize our findings as well as describe each variable.
* The data we obtained was extracted as a csv file consisting of 2,297 records (rows) and 32 fields (columns). 
* There is a mix of int64(2), object(25), and float64(6) data types as listed in the table below.  
* It is interesting to note that although there are 2,297 records, there are only 1,599 with unique usernames. 
* Only 77 records contained geo locations, 63 of which are unique. There are 5 different languages being represented, however English makes up 99.61% of the records. 
* There are multiple records which include NaN values, therefore these should be evaluated when running the analysis. 

These are the various python commands used to explore our data set. 
```
import pandas as pd
df = pd.read_csv("/content/clean_reMarkable2_tweets.csv")
df.describe()
df.count()
df.shape
df.isnull().sum()
print(df.nunique())
df.head(5)
df.info()
```

| #  | Column                    | Non-Null Count | Dtype   | Description |  
|--- | ------                    | -------------- | -----   | ----------- |
| 0  | Unnamed: 0.1              | 2297 non-null  | int64   | Index number |
| 1  |  tweet.id                 | 2297 non-null  | object  | Identifying number for Tweet posted |
| 2  | tweet.text                | 2297 non-null  | object  | Content of the posted tweet |
| 3  | tweet.attachments         | 532 non-null   | object  | Path for attachment. No attachment if NaN|
| 4  | tweet.author_id           | 2297 non-null  | float64 | Identifying number of person posting the tweet|
| 5  | tweet.context_annotations | 2297 non-null  | object  | Annotations related to posted tweet |
| 6  |  tweet.conversation_id    | 2297 non-null  | object  | Identifying number for conversation |
| 7  | tweet.created_at          | 2297 non-null  | object  | Date & time post was created in format YYYY-MM-DD HH:MM:SS+00:00 |
| 8  | tweet.entities            | 2182 non-null  | object  | Mentions/annotations/URL’s |
| 9  | tweet.geo                 | 77 non-null    | object  | Geographical location of device being used to make the post |
| 10 | tweet.in_reply_to_user_id | 951 non-null   | float64 | References the user who’s tweet is being replied to |
| 11 | tweet.lang                | 2297 non-null  | object  | Language used to make the post |
| 12 | tweet.public_metrics      | 2297 non-null  | object  | Lists the user’s counts for retweets, replies, likes, quotes |
| 13 | tweet.possibly_sensitive  | 2297 non-null  | object  | Uses “True” or “False” to categorize a tweet as sensitive or not |
| 14 | tweet.referenced_tweets   | 806 non-null   | object  | If post is responding to another tweet, the original tweet’s id is listed here |
| 15 | tweet.reply_settings      | 2297 non-null  | object  | Is reply being viewed by “everyone”, people “following”, or “mentionedUsers” |
| 16 | tweet.source              | 2297 non-null  | object  | App from which the posted tweet originated |
| 17 | tweet.withheld            | 0 non-null     | float64 | Was tweet withheld/not posted? |
| 18 | user.created_at           | 2297 non-null  | object  | Date & Time user was created in format YYYY-MM-DD HH:MM:SS+00:00 |
| 19 | user.description          | 2071 non-null  | object  | User self-description on twitter account |
| 20 | user.entities             | 1693 non-null  | object  | Entities (mentions, urls…) reflecting on Twitter account |
| 21 | user.id                   | 2297 non-null  | float64 | User’s identifying id# |
| 22 | user.location             | 1852 non-null  | object  | User’s physical location |
| 23 | user.name                 | 2297 non-null  | object  | User’s Self-identifying name as listed on Twitter account |
| 24 | user.pinned_tweet_id      | 997 non-null   | float64 | Identifying number for the pinned Twitter post |
| 25 | user.profile_image_url    | 2297 non-null  | object  | Url for user’s profile image  |
| 26 | user.protected            | 2297 non-null  | object  | Is user’s account protected? |
| 27 | user.public_metrics       | 2297 non-null  | object  | Metric’s visible on account such as count of followers, count of following, count of tweets, count of listed |
| 28 | user.url                  | 1423 non-null  | object  | User’s URL |
| 29 | user.username             | 2297 non-null  | object  | User’s username as listed on Twitter account |
| 30 | user.verified             | 2297 non-null  | object  | Is user a verified individual? |
| 31 | user.withheld             | 0 non-null     | float64 | Is user withheld/cancelled account |



## 2.3 Explore Data [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)
### Data Exploration Report

During the Data Exploration Report, we wanted to find insights and useful twitter reviews to get a better understanding on the customer's feedback from reMarkable 2. We created a WordCloud to help engage, educate and capture the attention of the audience to understand what keywords are frequently used about the product.

After a basic Exploratory Data Analysis, we were ready to create our WordCloud.
#### WordCloud Creation Process
1) Convert the Tweets as a "string"
2) Identify the combinations of words we have
3) Create stopwords so we can exclude the words that does not give us valuable insights
4) Creating the WordCloud with the following code
```
# Make sure that the dtype is string
text = " ".join(review for review in df['tweet.text'].astype(str))

# Find the combinations for words before creating a wordclout
print ("There are {} words in the combination of all cells in column tweet.text".format(len(text)))

# In case I want to exclude some words
stopwords = set(STOPWORDS)
stopwords.update(["remarkable", "remarkable2", "tablet", "notebook","paper","one","got","now","made","stuff","use","note","using"])

# Generate a WordCloud Image
wordcloud = WordCloud(stopwords=stopwords, background_color="white", width=800, height=400).generate(text)

# Display the generated image

plt.axis("off")
plt.figure( figsize=(25,10))
plt.tight_layout(pad=0)
plt.imshow(wordcloud, interpolation='bilinear')
plt.show()
```
![image](https://user-images.githubusercontent.com/99063922/162666080-8123ae44-3c28-44e5-9593-da85cb2cdd9e.png)
The larger a word's size in the cloud, the more frequently it is used. The word "love" is the largest, which indicates that the majority of the tweets are positive feedbacks towards the product.

#### Exploratory Analysis on Date

Utilizing the 'tweet.created_at' column we were able to analyze and find various insights regarding the date. First, we found the date range of the dataset is from 09/22/2019-04/05/2022. Additionally, we were able to find the days that contained the most Tweets. For example, in the figure below we can see that 11/05/2020 has the highest frequency of Tweets with a count of 21 posts.

![Unknown](https://user-images.githubusercontent.com/54599546/162803698-ae6f4212-86de-439f-8b5e-82f28e1977f5.png)

Furthermore, in the figure below we can see the count of Tweets aggregated by month.
![Unknown-3](https://user-images.githubusercontent.com/54599546/163023134-67dc2967-9d47-4633-8400-f45d62efe638.png)

#### Retweets, Replies and Likes

Utilizing the 'tweet.public_metrics' attribute from the original dataset, we were able to extract various metrics that gave us additional information regarding the Tweet such as how many likes/Rewteets it received. Additionally, this metric provided information on the user that Tweeted such as their following/followers list and how many Tweets they have posted on their account.

In the figure below, you can see that we were able to extract the tweets that were posted by users with the top 10 highest following. We can see that there is a user with 1,411,037 followers  who posted and is the user with the highest following in the dataset.

![Screen Shot 2022-04-11 at 11 44 53 AM](https://user-images.githubusercontent.com/54599546/162808159-c4809f70-7ee6-4687-b916-dfbb1b0a5c69.png)

#### Users
Lastly, with some additional exploratory analysis we were able to see the distribution of sources as well as the user's location in which they Tweeted.
Down below we found that the UK is the location with the most users that are posting about reMarkable. Additionally, we see that the Twitter Web App is the most popular source with almost 800 Tweets coming from that source followed by Twitter for iPhone and Twitter for Android.

![Unknown-2](https://user-images.githubusercontent.com/54599546/163023224-00c4bd6e-cd13-4f8e-b1b5-b412846e4f52.png)
![Unknown](https://user-images.githubusercontent.com/54599546/163023457-14ee9445-4b42-43fa-aaee-3d169acf9192.png)


## 2.4 Verify Data Quality [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)
### Data Quality Report
To examine the quality of the data, our team addressed the following questions in our analysis: 
 	- Is the data complete (does it cover all the cases required)?
	- Is it correct, or does it contain errors? 
	- Are there missing values in the data? 
	- Are there duplicates in the data? 

Below are the packages and python commands used to verify the quality of the dataset. 
```
import pandas as pd
from ydata_quality.erroneous_data import ErroneousDataIdentifier
df.isna().sum()
df.duplicated().sum()

edi = ErroneousDataIdentifier(df=df)
results = edi.evaluate()

warnings = edi.get_warnings()

edi.predefined_erroneous_data()
```

To answer whether the data is complete and if there are any missing values, we used the df.isnull().sum(). The dataset contains considerable rows of missing data over multiple columns. The missing values should be evaluated in the data preparation step.  

<img width="309" alt="Screen Shot 2022-04-12 at 11 23 35 AM" src="https://user-images.githubusercontent.com/61371423/163028717-f6fe56be-f9de-478c-8560-ec340d2d199a.png">

We found that there are no duplicate values in the data, therefore we can ensure that the data is unique. 

We installed the ydata_quality for deeper analysis on the quality of the data. We used ErroneousDataIdentifier to identify whether there are any possible erroneous data. The full evaluation of dataset reported that there are no erroneous found nor are there predefined erroneous data in our dataset. 

# Sprint 3: 
# Data Preparation Phase
## 3.1 Select Data [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)
Twitter API extracts a large number of variables, and many of them are not useful to our analysis and should be removed. This will help us stay focused on the variables that matter and speed up our analysis. The following is a list of variables we decided to remove: 

> ['tweet.id', 'tweet.attachments', 'tweet.author_id', 'tweet.context_annotations', 'tweet.conversation_id', 'tweet.geo', 'tweet.in_reply_to_user_id', 'tweet.lang', 'tweet.possibly_sensitive', 'tweet.referenced_tweets', 'tweet.reply_settings'  'tweet.withheld', 'user.description',  'user.entities', 'user.id', 'user.name', 'user.pinned_tweet_id', 'user.profile_image_url',  'user.protected', 'user.url', 'user.username', 'user.withheld']

A lot of these variables contain irrelevant information about users and the tweets such as the user id, tweet id, user name, etc. 

There are two columns we find especially interesting are ‘tweet.public_metrics’ and ‘user.public_metrics’. ‘tweet.public_metrics’ contains values such as likes, retweets, and replies, while ‘user.public_metrics’ contains following counts and follower counts. Once we tract those values into individual columns we will remove these two columns. 

One thing to be noted from the EDA is that while most tweets are from iPhone, Android phones, and the Twitter web app, there are a very small number amount of tweets that are from bots and marketing software platforms. However, these types of tweets are dismissably small, and we think they will not skew our analysis, so we decided not to remove them. 


## 3.2 Clean Data [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)
Due to the analytical model we are going to use, we need two different data sets with two different stages of cleaning. Most text mining algorithm requires stopwords removal and lemmatization. However, BERT natural language processing is extremely powerful where it can retain the semantic meaning of the sentence even with all the stopwords and different forms of the same word. 

The Initial Data Cleaning steps took care of most of the basic text cleaning, including properly encoding the text, removing links, @’s, and #’s. This level of cleaning is enough for analysis with BERT. However, other algorithms require a little more cleaning. 

Stopwords are words that do not provide too much semantic meaning to the sentence. We imported stopwords from the NLTK library and wrote a function for the stopwords removal. After removing the stopwords, we wrote another function that would lemmatize each tweet. And the reason why there is a need to lemmatize the words is that the same word can be in different variations, and that could skew the text mining processes if they are not formatted to their root word form.

```ruby
import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')
stop_words = stopwords.words('english')

# function to remove stopwords
def remove_stopwords(tweets):
  all_tweet = tweets.split(' ')
  rem_text = " ".join([i for i in all_tweet if i not in stop_words])
  return rem_text
  
from nltk.tokenize import word_tokenize
from nltk.corpus import wordnet
from nltk.stem import WordNetLemmatizer
import nltk
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('wordnet')
nltk.download('stopwords')

wl = WordNetLemmatizer()
 
# this is a helper function to map NTLK position tags
def get_wordnet_pos(tag):
    if tag.startswith('J'):
        return wordnet.ADJ
    elif tag.startswith('V'):
        return wordnet.VERB
    elif tag.startswith('N'):
        return wordnet.NOUN
    elif tag.startswith('R'):
        return wordnet.ADV
    else:
        return wordnet.NOUN

def lemmatizer(string):
    word_pos_tags = nltk.pos_tag(word_tokenize(string)) # Get position tags
    a=[wl.lemmatize(tag[0], get_wordnet_pos(tag[1])) for idx, tag in enumerate(word_pos_tags)] # Map the position tag and lemmatize the word/token
    return " ".join(a)
```


## 3.3 Construct Data [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)

This task includes additional data preparation operations such as producing derived attributes,
completing new records, and/or transforming/normalizing values. As mentioned above, when selecting the data for our model, we especially found the 
‘tweet.public_metrics’ and ‘user.public_metrics’ to be critical for our analysis. With the code below you can see how we were able to extract retweet, reply, and like metrics for each tweet. Additionally, we had the ability to find user information including their following count, how many accounts they follow, and tweets they have posted. Derived attributes created include 'tweet.retweet_count', 'tweet.reply_count', 'tweet.like_count', 'tweet.quote_count', 'user.followers_count', 'user.following_count', 'user.tweet_count', and 'user.listed_count'.

```ruby
# get retweet, reply and like count from tweet.public_metrics 
df['tweet.retweet_count'] = [re.findall(r'retweet_count\': (\d*)', x)[0] for x in df['tweet.public_metrics']]

df['tweet.reply_count'] = [re.findall(r'reply_count\': (\d*)', x)[0] for x in df['tweet.public_metrics']]

df['tweet.like_count'] = [re.findall(r'like_count\': (\d*)', x)[0] for x in df['tweet.public_metrics']]

df['tweet.quote_count'] = [re.findall(r'quote_count\': (\d*)', x)[0] for x in df['tweet.public_metrics']]

# get follwoing, follower and tweet count from user.public_metrics 
df['user.followers_count'] = [re.findall(r'followers_count\': (\d*)', x)[0] for x in df['user.public_metrics']]

df['user.following_count'] = [re.findall(r'following_count\': (\d*)', x)[0] for x in df['user.public_metrics']]

df['user.tweet_count'] = [re.findall(r'tweet_count\': (\d*)', x)[0] for x in df['user.public_metrics']]

df['user.listed_count'] = [re.findall(r'listed_count\': (\d*)', x)[0] for x in df['user.public_metrics']]

```

Additionally, for our model we created polarity and subjectivity features for sentiment analysis on the tweets. Utilizing the code below we had the ability to create two new features:

```ruby
# sentiment analysis
def detect_sentiment(text):
    blob = TextBlob(text)
    return blob.sentiment.polarity

def detect_subjectivity(text):
    blob = TextBlob(text)
    return blob.sentiment.subjectivity

# create new columns for polarity and subjectivity of the reviews
df['polarity'] = df['tweet.text'].apply(detect_sentiment)
df['subjectivity'] = df['tweet.text'].apply(detect_subjectivity)
```

Lastly, there was no need to generate records and/or normalize values for our model.

## 3.4 Integrate Data [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)

All data used in our model came from one dataset/source, so there was no need for joins or merging of tables!

## 3.5 Format Data [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)

The main modeling technique we are using is k-means clustering. Since k-means can only take numbers or vectors as inputs we need to first transform our data from text to text embeddings.

We are using a pre-trained BERT model (sentence-transformers) for getting the sentence embeddings of the tweets.

Our model doesn’t require a specific order of attributes.

Here is a snippet of the code we used for Data Formatting.
```python
# code for Data formatting
!pip install sentence-transformers

import pandas as pd
from sentence_transformers import SentenceTransformer
import tensorflow as tf

tweets = pd.read_csv('/content/clean_reMarkable2_tweets.csv')
tweets.head(1)


# Get the GPU device name.
device_name = tf.test.gpu_device_name()

# The device name should look like the following:
if device_name == '/device:GPU:0':
    print('Found GPU at: {}'.format(device_name))
else:
    raise SystemError('GPU device not found')
    
    
# this function uses simple BERT embedding
def simple_bert_embedding(data, model = 'all-MiniLM-L6-v2'):
  # use model
  embedder = SentenceTransformer(model)

  # load sentences into corpus
  corpus = data['tweet.text'].to_list()
  corpus_embeddings = embedder.encode(corpus)

  return corpus, corpus_embeddings
  
  
# embed tweets
corpus, corpus_embeddings = simple_bert_embedding(tweets)
print(corpus[0:5])
print(corpus_embeddings[0:5])


# Output: Tweets and their embeddings ready for clustering.

['two decades into the millenium, i find myself paying nontrivial for a tablet with the least amount of apps/capabilities i could find. the 90s dial-up internet kid in me has mixed feelings. excited to test whether less is truly more for my attention span', 'while at the airport re-reading clean code taking notes using the fantastic', "i use a boox note air2. it's like the remarkable2, but operates on android so you can use other apps not available on remarkable. it also has a backlight screen that you can adjust color temperature and brightness. the surface + pen nibs makes it feel very close to paper.", 'i had a remarkable2 tablet, tested it for a week and then realized i was willing to pay a little extra for an ipad with the same capabilities plus so much more. got the ipad instead with a paper feel protector and im obsessed!', "i love my remarkable2 and use it for hours most days. but writing/reading is all you can do on it and there is no color on the screen (just shades of gray). on my convertible laptop, i've happily used pdfannotator software for years, but it's not as paper-like as the remarkable."]
[[-0.00832761 -0.00102415  0.06460088 ... -0.02326298 -0.08229515
   0.02032411]
 [ 0.0150835  -0.00949365 -0.00077695 ...  0.05709019 -0.05652962
  -0.01889319]
 [-0.09136266 -0.02280454  0.02096646 ...  0.00760711 -0.06704685
   0.09065781]
 [-0.08097623 -0.10049953  0.0152678  ... -0.05365163 -0.05973168
   0.09055872]
 [-0.05229015 -0.01654954 -0.03774367 ... -0.0285043  -0.03328875
   0.03290348]]
    
```

We make sure to preserve all of the data about the Tweets by inlcuding the embeddings into the original DataFrame. The result is a csv file that is ready for further analysis.

```python
# add the embeddings column to the dataset
tweets['embeddings'] = list(corpus_embeddings)

# move the column to the beginning for ease of use
column_to_move = tweets.pop("embeddings")

# insert column with insert(location, column_name, column_value)
tweets.insert(1, "embeddings", column_to_move)
```

![image](https://user-images.githubusercontent.com/59128920/163668571-4e73acab-2fcf-48b5-baad-c7e09e7b6b6b.png)


# Modeling Phase
## 4.1 Selecting Modeling Techniquies [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)
Our main selected technique is K-mean clustering.

**A high-level overview of the process**

1. BERT for sentence embedding
2. K-means clustering
3. Calculate the centroid and sort the tweets by the distance from the centroid of the cluster.

**Modeling Assumptions**

1. We assume that BERT sentence embeddings adequately represent the meanings of the Tweets.
2. We assume that the Tweets that are embedded closest to the centroid of the cluster are the most representative of the cluster. This is important because it allows us to read only **a few Tweets** from each cluster and **quickly extract insights from a large number of Tweets** if needed.

**Code snippets and results**

To decide on the number of clusters we use a combination of **quantitative techniques such as elbow plot and dendrogram** and **human judgement** of the quality of the clusters. Since we are clustering text (unstructured data) it's importnant to make sure that the clusters and the number of **clusters make sense not only mathematically**.

Elbow plot
![image](https://user-images.githubusercontent.com/59128920/163669172-839d2f06-6234-4a16-a565-d70fa69dc83b.png)


Dendogram
![image](https://user-images.githubusercontent.com/59128920/163669180-6ff12da3-a2b8-4d6a-97d3-2f06a03e96dc.png)

PCA for dimensionality reduction and intuitive visualisation.

Although the 3 principal components explain only 20% of the variance and 2 principal components explain only 16% of the variance.  The cluster visualisation provides a more intuitive understanding of the distibution of the clusters. 

![image](https://user-images.githubusercontent.com/59128920/163670024-e14f2dc6-3ba7-4c83-a10f-c92059646b4b.png)


PCA of the clusters in 2d
![image](https://user-images.githubusercontent.com/59128920/163670310-a303ca6a-6dc9-466a-b959-cbd303d32a97.png)

PCA of the clusters in 3d
![image](https://user-images.githubusercontent.com/59128920/163670058-6eb3e755-f07e-419f-a755-508d0cc5f7a5.png)

**Centorid and the distance from it**
Unfortunately we can't visualise all 384 dimensions of the space. But we can calculate the centroids of the clusters and find the closest Tweets (the most representative of the cluster)

Code for getting the clusters and respective centroids.
```python
## Import libraries
from nltk.cluster import KMeansClusterer
import nltk

import numpy as np
from scipy.spatial import distance_matrix

def clustering_question(data,NUM_CLUSTERS = 6):

    sentences = data['tweet.text']

    X = np.array(data['embeddings'].tolist())

    kclusterer = KMeansClusterer(
        NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance,
        repeats=25,avoid_empty_clusters=True)

    assigned_clusters = kclusterer.cluster(X, assign_clusters=True)

    data['cluster'] = pd.Series(assigned_clusters, index=data.index)
    data['centroid'] = data['cluster'].apply(lambda x: kclusterer.means()[x])

    return data, assigned_clusters

clustering_question(tweets, 6)
```

Code for calculating the distance

```python
# calculating the distance from te centroid to find the most representative sentences
def distance_from_centroid(row):
    # type of emb and centroid is different, hence using tolist below
    return distance_matrix([row['embeddings']], [row['centroid'].tolist()])[0][0]


# Compute centroid distance to the data
tweets['distance_from_centroid'] = tweets.apply(distance_from_centroid, axis=1)
```

**Sort tweets by the least distance frrom the centroid**

Even at a glance we can see that closer embeddings are more relevant.
![image](https://user-images.githubusercontent.com/59128920/163670525-21d0b96b-5621-4862-a3bf-21a5a36b7e31.png)


This information allows us to extract customer insights from large ammounts of data to drive business insights and recommendations.


## 4.2 Generate Test Design [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)
We do not need to generate a test design for our project since we will be using the K-means clustering model. The training phase for K-nearest neighborhood (kNN) classification is faster than other classification algorithms, so there is no need to train the model for generalization. kNN does not need training since it relies on observable data similarities and distance metrics to generate predictions. This theory means the model assumes similar things exist in close proximity to each other in the feature space; it makes predictions based on objects in the clusters.  

## 4.3 Build Model [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)
As stated in section 4.1, our group will build a kNN model for the project. This section will build on the kNN model presented in section 4.1. Instead of using 6 clusters, we will test the model using 10, 15, and 25 clusters. 

**The code we used to define the kNN model using 10 clusters. The same piece of code is also used for 15 and 25 clusters.**

### Using 10 clusters.

```
def clustering_tweets(data,NUM_CLUSTERS = 10):

    sentences = data['tweet.text']

    X = np.array(data['embeddings'].tolist())

    kclusterer = KMeansClusterer(
        NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance,
        repeats=25,avoid_empty_clusters=True)

    assigned_clusters = kclusterer.cluster(X, assign_clusters=True)

    data['cluster'] = pd.Series(assigned_clusters, index=data.index)
    data['centroid'] = data['cluster'].apply(lambda x: kclusterer.means()[x])

    return data, assigned_clusters

clustering_tweets(tweets, 10)



tweets.head()
```

**PC2 of 10 clusters in 2D.**

<img width="395" alt="Screen Shot 2022-04-25 at 7 15 41 PM" src="https://user-images.githubusercontent.com/61371423/165240060-6aa94b90-b426-4bfc-9751-408835f484c2.png">


**Code for calculating distance from the centroid to find the most representative sentences and sort the tweets by distance from centroid.**

```
# calculating the distance from te centroid to find the most representative sentences
def distance_from_centroid(row):
    # type of emb and centroid is different, hence using tolist below
    return distance_matrix([row['embeddings']], [row['centroid'].tolist()])[0][0]


# Compute centroid distance to the data
tweets['distance_from_centroid'] = tweets.apply(distance_from_centroid, axis=1)

sorted_tweets_10 = tweets.sort_values(by = ['cluster', 'distance_from_centroid'])[['tweet.text', 'cluster', 'distance_from_centroid']]
```

**Result of sorted_tweets_10.**

<img width="641" alt="Screen Shot 2022-04-25 at 7 16 36 PM" src="https://user-images.githubusercontent.com/61371423/165240174-c5448d1f-f3da-4e24-86a2-49ced10ca6d7.png">

**Code to show top three tweets from each cluster.**

```
# show top 3 from each cluster
top_tweets = []
n_clusters = sorted_tweets_10.cluster.max()+1
#print(n_clusters)

for cluster in range(n_clusters):
  #print(cluster)
  for top in range(3):
    top_tweets.append(sorted_tweets_10[sorted_tweets_10['cluster']==cluster].iloc[top,:])
    #print(sorted_tweets[sorted_tweets['cluster']==cluster].iloc[top,:])
  
top_tweets = pd.DataFrame(top_tweets)
top_tweets
```

**This screenshot only shows the top three tweets in three clusters. The results show top three tweets for all clusters.**

<img width="711" alt="Screen Shot 2022-04-25 at 10 56 25 PM" src="https://user-images.githubusercontent.com/61371423/165240662-3633c704-3035-42b9-b239-7e6a474595ad.png">


### Using 15 clusters.

**PC2 of 15 clusters in 2D.**

<img width="399" alt="Screen Shot 2022-04-25 at 7 18 33 PM" src="https://user-images.githubusercontent.com/61371423/165241107-dbb1d492-3235-48dd-b3f9-ce906d2742ff.png">



**Result of sorted_tweets_15.**

<img width="675" alt="Screen Shot 2022-04-25 at 10 58 06 PM" src="https://user-images.githubusercontent.com/61371423/165241196-fb6e482f-943e-476a-a8e0-9f92887617ad.png">

**Top three tweets in each cluster of fifteen clusters.**

<img width="651" alt="Screen Shot 2022-04-25 at 10 59 19 PM" src="https://user-images.githubusercontent.com/61371423/165241374-297c8633-eaf7-4ffd-b6bc-992aab5838e5.png">

### Using 25 clusters.


**PC2 of 15 clusters in 2D.**

<img width="398" alt="Screen Shot 2022-04-25 at 11 08 06 PM" src="https://user-images.githubusercontent.com/61371423/165241745-f5b8fac4-0234-4dd6-bbb1-3195b6b0c031.png">

**Result of sorted_tweets_25.**

<img width="656" alt="Screen Shot 2022-04-25 at 11 09 44 PM" src="https://user-images.githubusercontent.com/61371423/165241838-54ba17e1-583f-4b7d-9119-69ae02b1dd23.png">

**Can not produce results to display top three tweets for kNN model with 25 clusters since the index is out of bounds. This error means that the the model is trying to use memory that is beyond the scope of the index.**


## 4.4 Assess Model [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)
One of our data mining success criteria was to ensure that we were able to use the mined data to run models, which in our case was met. In a technical sense, we are able to use the mined data to run models in an effort to inform our business objective of incresaing sales. The data we obtained is usable as valid input into the models we created. In the previous step, we tested the model with 6, 10, 15, and 25 clusters. 
The models featuring 6, 10, and 15 clusters ran properly and the findings pointed out similar ideas within the clusters. In terms of quality, increasing the number of clusters did not prove beneficial, since the same remarks were being repeated across clusters. And the model with 25 clusters gave us a run error since the index was out of bounds. Therefore we conclude that the lower amount of clusters is the best model. This was also backed up by taking into account the results of our elbow for k-means clustering graph, which pointed to a lower number of clusters. 


# Evaluation Phase
## 5.1 Evaluate Results [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)
Upon further review of the original models, we have found that we started with the incorrect segment of data/tweets. We sorted out the tweets containing positive tweets and used those reviews to shape our models. Although informative in determining what our customers are satisfied with, the findings did not inform our business objective of finding flaws/pain-points which could be improved upon to drive up sales. 

```
# select only negative reviews to identify the problems
tweets = tweets[tweets['polarity'] < 0]
tweets.shape
```

Once this line of code was fine tuned to sort out the tweets with negative sentiment, we re-ran the models again and using the elbow for kmeans clustering function, determined that the more appropriate number of clusters was 5.

![image](https://user-images.githubusercontent.com/78009006/165477563-f2c05611-5b0b-4ddf-9842-16c75bc043ac.png)

Once we ran the model, we were able to generate valuable insight from the mined data. Below is a table listing the top three tweets from each cluster. The two main areas of focus, based on our findings, need to be improved customer support and accurate/more efficient delivery of our product. It makes sense that some aspects of selling a product are out of our control such as the occasional defective item. However the manner in which we handle the resolution of said issue makes all the difference. In today's day-and-age instant gratification is the norm. The faster a tablet gets to our customer, the better the purchasing experience will be. 



|index  |tweet.text	    |cluster	       |distance_from_centroid|
|-------|-------------------|------------------|--------------------------------|
|225|	back in june, when i felt the need for something to look forward to, and was surrounded by post-its and burning through notebooks at a crazy rate, i ordered a as a present to myself. it's finally arriving on tuesday. i'm expecting instant productivity nirvana obvs.	|0|	0.7479107615766468|
|83|	i have a serious "i want it now" problem. i don't like waiting. when you spend that kinda money on a product you expect a little more promptness in shipping. the delay in shipping is making me want to cancel the order. ugh	|0|	0.6822079327264841|
|182|	neil, i'm thinking about charging it back as well. it makes me sad because i love but right now their lack of response is all that's remarkable. :( i suppose i'll charge it back and then order another ugh. this feels bad.	|0|	0.794111177608954|
|221|	i recieved a disappointing email from regarding the delayed shipping of my remarkable2. i was given a rather vague eta of 'the next few weeks' for the price of this product i'd expect better.	|1|	0.5342823665889028|
|152|	issues with my remarkable2. contacted customer support. seem to be stuck in an endless loop with them being incredibly unhelpful. it seems as if other customers have had similar problems. terrible customer service.	|1|	0.5767891746511663|
|251|	so my remarkable2 is expected to ship in a couple of days. been waiting since may.. let us see what is the fuss is all about	|1|	0.5637665744285064|
|86|	is a terrible product - it was delivered damaged, and customer support refused to take it back or exchange it.	|2|	0.13148246188652704|
|87|	is a terrible product - it was delivered damaged, and customer support refused to take it back or exchange it.	|2|	0.13148246188652704|
|88|	is a terrible product - it was delivered damaged, and customer support refused to take it back or exchange it.	|2|	0.13148246188652704|
|69|	6 weeks awaiting a refund, ignored support requests, bad product even worse service and reputation is worthless	|3|	0.681137409810351|
|227|	their customer service really sucks. they sent me a faulty product so i raised a support request as soon as i opened my still no response at all.	|3|	0.6910516746026814|
|38|	unacceptable to have no live customer service. got tablet for wife for xmas, completely defective. tried processing return, which was rejected for an unexplained reason after 4 days. told to contact tech support, now supposed to wait another 24 hours for response	|3|	0.6956269819853677|
|230|	surprise surprise! the boox note air has my deep guide hardly going back to his no point buying pretty device with the shit software and customer service.	|4|	0.29067039707654485|
|231|	surprise surprise! the boox note air has my deep guide hardly going back to his no point buying pretty device with the shit software and customer service.	|4|	0.29067039707654485|
|233|	surprise surprise! the boox note air has my deep guide hardly going back to his no point buying pretty device with the shit software and customer service.	|4|	0.29067039707654485|


## 5.2 Review Process [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)
At this point, the resulting models appear to be satisfactory and satisfies the needs so far, in order to achieve our goal of increasing sales. Our high level overview of the process consists of Bert for sentence embedding, K-means clustering, and calculate the centroid and sort thr tweets by distance from the centroid of the cluster. Now that we are able to collect the top three tweets for each of the clusters we have, we can use this information to understand what people think about our product. This data will allow us to identify our strengths, and keep building on them, as well as making adjustments for our weaknesses.

The quality of our models are satisfactory since we are able to draw valuable information. The attributes that we used were "tweet.public_metriccs" and "user.public_metrics". These attributes contains values such as likes, retweets, replies, following count and follower counts. The attributes are available for future analyses as well. 

There are some activities and tasks that has been overlooked that is important to identify:
- Discussion with Business Stakeholders
- Obtain some revenue data from reMarkable
- Not able to get useful review data
- Obtain information on reviews from other sources, e.g. blogposts


## 5.3 Determine Next Steps [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)

The next steps for our project will build on the tasks that were overlooked previously. We just got ahold of the VP of Marketing from reMarkable, who has been a part of the team for a very long time. Being able to get in touch with him could help us with some insights, and hopefully give us extended clarity on the deployment. We were told that he cannot go too into details about the future business plan, but that he will be able to give his feedback and perhaps some tips before our deployment. 

List of future actions will be:
- Discuss with Sigurd Gran-Jansen (VP of Marketing), to hopefully gain some insights before launching our deployment. Since we potentially have the ability to get in touch with him, it is an opportunity that we have to capitalize on.
- Due to the challenge of obtaining useful review data, we need to collect more review data from other sources. If we can gather more data that can lead us to achieve our goal of increasing sales, it is something we can look into before finishing our project.


# Sprint 4: [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)
# Deployment Phase [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)
## 6.1 Plan Deployment [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)

For the final deployment of the model, we performed the following:

1. Recollected all of the tweets that mention reMarkable2
2. Cleaned the data
3. Performed feature engineering
4. Performed clustering and selected 3 top tweets for each cluster
5. Identified the main topics, ranked them by importance, and provided details and actions to improve.
6. Presented the findings both in a presentation and in a dashboard for the final users (decision-makers).

As a result of the above, we were able to identify 20 topics: 10 with positive sentiment and 10 with negative sentiment. 
We summarized our recommendations on a few most impactful topics. 



Alternative plans for deployment include the following:

1. Increase the number of tweets for analysis by increasing reMarkable’s brand presence on Twitter.
2. Scrape blog posts and reviews on reMarkable2 and use the existing models for the analysis. 


Each distinct knowledge or information result from our model is stored in a separate excel file and is ready to be visualized and propagated to users.

The knowledge will be propagated to users through the final presentation and an interactive dashboard.


To monitor the use of the results we are going to track the number of views of the dashboard and which department those views came from. 

We also created dashboards that track relevant business KPIs alongside our recommendations to measure the benefits of our interventions. 

Dashboard 1:

https://public.tableau.com/app/profile/daniel.enciso/viz/ReMarkable_Sales_Dashboard/Sales_Dashboard?publish=yes


Dashboard 2: 

https://public.tableau.com/views/Combined_16516139118450/Dashboard1?:language=en-US&:display_count=n&:origin=viz_share_link









Our topic generation model would be deployed by the product development team as well as the marketing team, but it will also involve the new Twitter social media manager that we recommend reMarkable to hire. ReMarkable’s Twitter manager will reply to tweets to reMarkable on a daily basis. Once a week the Twitter manager will use Twitter API to get all the relating tweets from that week and put them through our model to generate topics. The top tweets of each topic will then be sent to the product development team and the marketing for them to gain insights into immediate customer feedback and respond. The dashboards we developed are intended for the CEO and general manager. They will use the dashboard to monitor the overall brand perceptions, sales, returns, and customer service status. 

We will measure the benefit of our model in different ways. In the short term, we will measure benefits by monitoring the customer service ticket count and satisfaction rate as well as the Twitter customer sentiment. And in the long run, we will measure the benefit by comparing the same period sales of reMarkable 3 to reMarkable 2. 

One of the biggest issues we might encounter is that during the initial deployment we might not be able to obtain enough new tweets fast enough. It will take some time for reMarkable to establish a good Twitter presence that will encourage customers to provide feedback. 



## 6.2 Plan Monitoring & Maintenance [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)

Our project uses the K-means Clustering model there are some dynamic aspects of the dataset that could impact the model. The size and distribution of the datasets could change the effectiveness of the k Means clustering model. K-means Clustering algorithm is an unsupervised learning method that requires a lot of fine tuning and has limitations. This type of model does not work well with small datasets and it does not perform well on datasets which has uniform distribution. Some limitations of K-means are:
•	It gives more weight to bigger clusters
•	It assumes spherical shapes of clusters
•	It does not have an intrinsic measure for uncertainty so if there is overlap between clusters, the model will have difficulty determining which cluster to assign each data point 
•	It may cluster data even if it cannot be clustered, as seen in the case with datasets with uniform distributions

The K-means model may not work well with small datasets so to ensure more robust analysis and data insights. To tackle this issue, reMarkable may need to interact more with customers on Twitter or post more tweets. 

The K-means Clustering model is a classification tool, thus analyzing accuracy is not effective, however, accuracy can be evaluated when the data is labeled. Accuracy can be evaluated with a confusion matrix and classification report. Accuracy can be monitored by checking the weighted averages of precision, recall, and f-1 score. 

The model should not be used when we are presented with a small dataset or a uniform dataset. Additionally, the K-means clustering model does not work well when there are outliers or large number of dimensions in the data.

As we set out on this project, our first business objective was to identify pain points from the current product, reMarkable2, in order to aid the engineering department when creating the next iteration of the tablet. One change in business objectives to consider moving forward, is not focusing solely on the next version of the product, but possibly software updates as well. Focusing on software updates to improve the current functionality would be a more efficient way to improve our customers’ experience, without the need to have them purchase a new item. Our customers would be less likely to leave our company since they would be improving the item they currently hold, without the need to spend money on a new product altogether. Additionally, as we continue to use this model moving forward, the business objective may need to change from focusing on the pain points, to also taking into consideration the points that our customers enjoy so that we don’t mistakenly change what our customers appreciate. Our second business objective was to gain insight into our customer base in order to segment our customers so that we can more accurately target them. As we move forward, we will need to update this segmentation since technology trends are everchanging and we must be able to stay ahead of our competitors in order to keep our customers happy. 

In order to monitor and maintain our business objectives, we will need to create and analyze tables clearly listing the pros and cons of the current iteration of the tablet. Setting clear indicators of what can be actioned on immediately through software updates versus what would need to be implemented in the next iterations would be best, since that would set a clear path for our engineers. Urgent software updates are easier to roll out than creating the next version of the tablet. In regards to segmenting our customers, we will need to have an individual or a team keep up with the current trends in the market in order to provide up to date information. We will need to know when new trends arise in order to adjust our segmenting and marketing efforts.


## 6.3 Product Final Report [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)
[Here is the slides for the final presentation!](https://github.com/LMU-MSBA/bsan-6080-reMarkable/blob/main/reMarkable%20Presentation.pdf)

## 6.4 Review Project [↑](https://github.com/LMU-MSBA/bsan-6080-reMarkable#table-of-content)

To review our project, groupmembers shared their thoughts on what their experience was working on this. Some challenges that we faced with a big team is collaborating when the group number is high. More specifically, it was sometimes challenging doing a task that is built up from another teammates code. Due to difference in coding styles and preferances, it can take some extra time to familiarize yourself with the enviornment and continue the code. However, this process will allow us to grow our knowledge even more, as well as communicacting with our team to interpret the codes. Overall, we enjoyed working with this project since it enables us to showcase our strategic thinking and how to apply business intelligence to technical problems. 

Analyze the process

As a group, it eas exciting to see our project develop and see what we could accomplish! We had the ability to extract UGC from Twitter on reMarkable2 to understand how user's view the product. From the beginning our team had to develop various skills as a group and learn how to work with each other. There was a constant need for commmunication as we were working on the various parts of the project. One of the most challenging parts of the project was ensuring everyone was on the same page as we had a larger group with 6 team members. With this, our team also had some advantages as we had multipe members with different strengths. Some were more tedchnical, some great with communication and project management. Overall, we had the ability to complete a project we are proud of and found insights that we believe useful to reMarkable. In all, this project was extremely beneficial for all of us as we learned not only how to run a thorough model on UGC, but we also learned how to work with a larger gorup as well as how to apply strategical thinking to a real world company that we were able see the impact our analysis could have on this company.


